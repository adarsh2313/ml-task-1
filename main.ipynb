{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Import all the other files and necessary modules\n",
    "import numpy as np\n",
    "import activation\n",
    "import convolution\n",
    "import maxpool\n",
    "import fullyconnected\n",
    "import utility\n",
    "import createdataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Initialise filters and weights\n",
    "F1,b1,F2,b2 = convolution.init_filters()\n",
    "weights = fullyconnected.init_weights()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Generate dataset X and Y\n",
    "X = createdataset.create_images() / 255             # Data is normalised by dividing each value by 255.. so finally each value is between 0 and 1\n",
    "Y = np.zeros((1200,3), dtype = int)\n",
    "for i in range(400):\n",
    "    Y[i,0] = 1\n",
    "for i in range(400,800):\n",
    "    Y[i,1] = 1\n",
    "for i in range(800,1200):\n",
    "    Y[i,2] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def create_minibatches(X, Y, batchsize):\n",
    "    assert X.shape[0] == Y.shape[0]\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, X.shape[0] - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield X[excerpt], Y[excerpt]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "for i in range(70):\n",
    "    \n",
    "    for batch in create_minibatches(X, Y, batchsize = 24):\n",
    "        X_mini, Y_mini = batch\n",
    "    \n",
    "    Z1, cache_conv1 = convolution.forward(X_mini,F1,b1,stride=1,pad=1)                    # First layer of convolution\n",
    "    A1 = activation.relu_frwrd(Z1)                                                        # Relu activation is used\n",
    "    A1m, cache_maxpool1 = maxpool.forward(A1, f=2, stride=2)                              # First layer of maxpool\n",
    "    Z2, cache_conv2 = convolution.forward(A1m,F2,b2, stride=1, pad=1)                     # Second layer of convolution\n",
    "    A2 = activation.relu_frwrd(Z2)                                                        # Relu activation is used\n",
    "    A2m, cache_maxpool2 = maxpool.forward(A2, f=2, stride=2)                              # Second layer of maxpool\n",
    "    X_f = utility.flatten_forward(A2m)                                                    # Flatten the layer in order to feed to fully connected layer\n",
    "    cache_fc = fullyconnected.forward(X_f, weights)                                       # Fully connected forward propagation\n",
    "    cost = fullyconnected.compute_cost(cache_fc['A4'],Y_mini.T)                           # Compute cost\n",
    "    error = np.mean(np.square(cache_fc['A4']-Y_mini.T))                                   # Compute error\n",
    "    weights, dA = fullyconnected.backward(cache_fc,Y_mini.T,weights,alpha = 0.05)         # Fully connected backward propagation\n",
    "    dA = utility.flatten_backward(dA,A2m.shape)                                           # De-flatten the layer to perform CNN and Maxpool backprop\n",
    "    dA = maxpool.backward(dA,cache_maxpool2)                                              # Maxpool 2nd layer backprop\n",
    "    dA, dF2, db2 = convolution.backward(dA, cache_conv2)                                  # Conv 2nd layer backprop\n",
    "    F2,b2 = convolution.updatefilters(F2,b2,dF2,db2,alpha = 0.05)                         # Update F2 and b2\n",
    "    dA = maxpool.backward(dA, cache_maxpool1)                                             # Maxpool 1st layer backprop\n",
    "    dA, dF1, db1 = convolution.backward(dA, cache_conv1)                                  # Conv 1st layer backprop\n",
    "    F1,b1 = convolution.updatefilters(F1,b1,dF1,db1,alpha=0.05)                           # Update F1 and b1\n",
    "\n",
    "    if i%10 == 0 :\n",
    "       print('Cost after '+str(i)+' iterations is '+str(cost))\n",
    "       print('Accuracy = ' + str(100-error))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cost after 0 iterations is 0.3750024859766371\n",
      "Accuracy = 99.74999834268225\n",
      "Cost after 10 iterations is 0.36160990620352634\n",
      "Accuracy = 99.75892672919765\n",
      "Cost after 20 iterations is 0.35085080210850533\n",
      "Accuracy = 99.766099465261\n",
      "Cost after 30 iterations is 0.3427437597889969\n",
      "Accuracy = 99.77150416014067\n",
      "Cost after 40 iterations is 0.337210612086806\n",
      "Accuracy = 99.77519292527546\n",
      "Cost after 50 iterations is 0.33414608893357034\n",
      "Accuracy = 99.77723594071095\n",
      "Cost after 60 iterations is 0.33336157417778955\n",
      "Accuracy = 99.77775895054815\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Final filters and weights is loaded to Final weights.npy file\n",
    "\n",
    "final_weights = {}\n",
    "final_weights['F1'] = np.asarray(F1)\n",
    "final_weights['b1'] = np.asarray(b1)\n",
    "final_weights['F2'] = np.asarray(F2)\n",
    "final_weights['b2'] = np.asarray(b2)\n",
    "\n",
    "np.save('Final weights', final_weights)\n",
    "np.save('Final weights', weights)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}